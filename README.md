# CS431 Project: Image Generation with Adapters

This repository contains the source code, training configs, and resources for the CS431 project. The project explores and implements **IP-Adapter** and **UniControlNet** for controlled image generation.

## üìÇ Repository Structure

* `IPAdapter/`: Source code and scripts for IP-Adapter.
* `UniControlNet/`: Source code and scripts for UniControlNet.
* `So s√°nh ƒë·ªãnh t√≠nh/`: Qualitative comparison results.
* `·∫¢nh demo/`: Demo images generated by the models.
* `Demo.ipynb`: Jupyter Notebook for demonstrating the project results.
* `B√°o c√°o ƒë·ªì √°n CS431.pdf`: Final project report.
* `CS431_Project_slide.pdf`: Presentation slides.

## üîó Model & Resources

Pre-trained models, datasets, video demo and checkpoints can be found here:
üëâ [**Google Drive Folder**](https://drive.google.com/drive/folders/1Eou2X4FloFdXRUU4SOOLSx4tQ6FsF6CF)

---

## ‚öôÔ∏è Configuration & Hyperparameters

Below are the detailed configurations used for training the models in this project.

### 1. Global Environment
| Parameter | Value |
| :--- | :--- |
| **Base Model** | `runwayml/stable-diffusion-v1-5` |
| **Image Encoder** | `openai/clip-vit-base-patch32` |
| **Precision** | `fp16` (Mixed Precision) |
| **Accelerator** | Distributed Data Parallel (DDP) |
| **Num Processes** | 2 |

### 2. Training Configurations
Parameters used for training IP-Adapter and UniControlNet on the CC3M dataset.

| Hyperparameter | IP-Adapter Config | UniControlNet Config |
| :--- | :--- | :--- |
| **Script Path** | `IPAdapter/tutorial_train.py` | `UniControlNet/src/train/train_global_adapter_diffusers.py` |
| **Dataset** | CC3M WebDataset | CC3M WebDataset |
| **Resolution** | 512 | 512 |
| **Batch Size** | 4 | 4 |
| **Learning Rate** | 1e-4 | 1e-4 |
| **Weight Decay** | 0.01 | 0.01 |
| **Epochs / Steps** | 1 Epoch (363,750 steps) | Max steps: 363,750 |
| **Dataloader Workers** | 4 | 4 |
| **Drop Probability** | N/A | Text: 0.5 / Global: 0.5 |

---

## üöÄ How to Run

To execute the project training using the configurations above, refer to the following scripts:

1.  **Training IP-Adapter:**
    Run `IPAdapter/tutorial_train.py` via `accelerate launch`.

2.  **Training UniControlNet:**
    Run `UniControlNet/src/train/train_global_adapter_diffusers.py` via `accelerate launch`.


